---
title: "Part Two: Analyzing CPI with Python and R"
description: "TBD"
author:
  - name: Mickey Rafa
    url: https://mrafa3.github.io/
    #orcid: 0000-0002-5300-3075
date: 09-11-2024
categories: [Python, pandas, api, data-viz, plotnine, R, Quarto, regression, matplotlib] # self-defined categories
#citation: 
 # url: https://mrafa3.github.io/posts/2024-07-15-wikipedia-international-mens-soccer/ 
code-annotations: hover
# image: cpi_plot.png
draft: true # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
editor: 
  markdown: 
    wrap: 72
---

# Introduction

The `pandas-datareader` package is a powerful tool for easily accessing financial and economic data through various APIs. In this post, we'll explore how to use it to fetch data from FRED (Federal Reserve Economic Data). Then, I'll show some visualization techniques using `matplotlib`, `plotnine`, and `ggplot2`.

## Setup



```{r load_libraries, include=TRUE}
library(tidyverse)
library(fredr)

# fredr_set_key('YOUR_API_KEY_HERE')
```


```{r category_children, include=TRUE}
# look more into the category_id
cpi_categories <- fredr_category_children(category_id = 9)
```


```{r}
get_series_for_category <- function(category_id) {
  fredr_category_series(category_id = category_id) %>%
    select(id, title)
}

cpi_series <- map_df(cpi_categories$id, get_series_for_category)

cpi_series <- cpi_series %>% 
  filter(str_detect(title, '^Consumer Price Index for All Urban Consumers')) %>% 
  filter(str_detect(id, "^.{8}$"))
```


```{r}
# fetch_cpi_data <- function(series_id) {
#   fredr(
#     series_id = series_id,
#     observation_start = as.Date("2016-01-01"),
#     observation_end = as.Date("2024-09-17")
#   ) %>%
#     select(date, value) %>%
#     rename(!!series_id := value)
# }
# 
# cpi_data <- map_df(cpi_series$id, fetch_cpi_data) %>%
#   reduce(full_join, by = "date")
```


1. If it's your first time running code with these libraries, you'll need to first use the pip install command. Since these are already installed for me locally, I can just import.

Next, I'll set a variable for the time frame that I'd like to use for this demonstration.

```{python set_times, include=TRUE}
start = datetime(2010, 1, 1)
end = datetime.now()
```

# Fetching Data from the Federal Reserve

Let's fetch the US GDP data from Federal Reserve Economic Data (FRED) API:



And I'll show a quick plot with `matplotlib`. It's that fast to go from gathering data to creating a viz!


```{r load_r_packages, include=TRUE, echo=FALSE, output=FALSE}
library(tidyverse)
library(reticulate)
library(tidymodels)
```

```{r reticulate_python_to_r, include=TRUE}
# colorado_unemployment <- reticulate::py$colorado_unemployment
```

# Analysis of the Consumer Price Index 

The Federal Reserve is the resource for gathering all data related to the Consumer Price Index. There are many ways to look at this, including decomposing by the type of good, looking at it over different horizons or localities, and more. 
For this demo, I'll just look at the U.S. city average for all urban consumers.[^1] Again, I'll use `pandas_datareader` and pass through some simple arguments to fetch the data.

[^1]: The Federal Reserve website is a great place to comb through to see all the available data (https://fred.stlouisfed.org/). 

```{python get_cpi_data, include=TRUE}
cpi = pdr.get_data_fred('CPIAUCSL', start=start, end=end).reset_index()
```
For this section, I'd like to work in R, so I'll use `reticulate::` to make it an R object.

```{r retculate_cpi, include=TRUE, echo=FALSE}
cpi <- reticulate::py$cpi
```

When you're working with CPI data, it is common to index the data, or compare recent values to a historical value. I'll create an `indexed_cpi_2016` field, along with a `date_seq` field to allow some simple linear models.

```{r filter_2016, include=TRUE, echo=FALSE}
cpi <- cpi %>% 
  filter(DATE > '2016-01-01') %>% 
  mutate(indexed_cpi_2016 = CPIAUCSL / first(CPIAUCSL))
```

```{r ggplot_cpi, include=TRUE, fig.width=10, fig.height=6.2, fig.align='center'}
cpi %>% 
  ggplot(aes(x=DATE,
             y=indexed_cpi_2016)) + 
  geom_line() + 
  labs(title='Consumer Price Index in the United States',
       subtitle='January 2016 to August 2024, Index = January 2016',
       caption='Source: U.S. Federal Reserve\nIndicator = CPIAUCSL',
       x='',
       y='') + 
  theme_minimal()
```

This plot shows a clear rise in the indexed CPI from 2016 to present day. What stands out, too, is that there appear to be some distinct trends (possibly three) -- pre-pandemic, pandemic, and post-pandemic. I'd like to extend this mini-analysis to find the slopes of these periods and plot them on the above graphic.

```{r cpi_add_date_seq, include=TRUE, echo=FALSE}
cpi <- cpi %>% 
  arrange(DATE) %>%
  mutate(date_seq = row_number())
```

To do so, I'll create a function and use `tidymodels::` to build linear models that I can easily create and compare with one another.

```{r fit_cpi_model, include-TRUE}
fit_cpi_model <- function(df) {
  lm_model <- linear_reg() %>% set_engine("lm") # <2>
  lm_fit <- lm_model %>% # <3>
    fit(indexed_cpi_2016 ~ date_seq, data = df) # <3>
  return(lm_fit)
}
```

2. This sets up the model type as a simple linear model.
3. This is the function that will take in the `df` parameter and run the model

These create a `parsnip::` model object, which we can then explore the model results in tidy dataframes.

```{r run_cpi_models, include=TRUE}
lm_1 <- fit_cpi_model(cpi %>% filter(DATE <= '2020-03-01'))
lm_2 <- fit_cpi_model(cpi %>% filter(DATE > '2020-03-01' & DATE <= '2022-06-01'))
lm_3 <- fit_cpi_model(cpi %>% filter(DATE > '2022-06-01'))
```

The `broom::tidy()` function returns a row for each coefficient your model, which I'll use to compare the slopes of the different periods.

```{r tidy_lms, include=TRUE, echo=FALSE}
tidy_lm_1 <- tidy(lm_1) %>% as.data.frame() %>% mutate(model = 'Period 1') %>% select(model, everything())
tidy_lm_2 <- tidy(lm_2) %>% as.data.frame() %>% mutate(model = 'Period 2') %>% select(model, everything())
tidy_lm_3 <- tidy(lm_3) %>% as.data.frame() %>% mutate(model = 'Period 3') %>% select(model, everything())
```

```{r show_slopes, include=TRUE, echo=FALSE}
bind_rows(tidy_lm_1, tidy_lm_2, tidy_lm_3) %>% filter(term == 'date_seq') %>% select(1:3)
```

```{r slope_objects, include=TRUE, echo=FALSE}
slope_1 <- tidy_lm_1 %>% filter(model == 'Period 1', term == 'date_seq') %>% pull(estimate)
slope_2 <- tidy_lm_1 %>% filter(model == 'Period 2', term == 'date_seq') %>% pull(estimate)
slope_3 <- tidy_lm_1 %>% filter(model == 'Period 3', term == 'date_seq') %>% pull(estimate)
```

Here's what this tells us:

*  Pre-pandemic slope of .002
*  Pandemic-era slope of .006
*  Post-pandemic slope of .003

This is also apparent visually, as seen below.

```{r ggplot_cpi_polished, include=TRUE, fig.width=10, fig.height=6.2, fig.align='center'}
cpi %>% 
  ggplot(aes(x=DATE,
             y=indexed_cpi_2016)) + 
  geom_line() + 
  geom_smooth(data=. %>% filter(DATE <= '2020-03-01'),
              formula=y~ x,
              se=FALSE,
              color='blue',
              method='lm') + 
  geom_smooth(data=. %>% filter(DATE > '2020-03-01' & DATE <= '2022-06-01'),
              formula=y~ x,
              se=FALSE,
              color='orange',
              method='lm') + 
  geom_smooth(data=. %>% filter(DATE > '2022-06-01'),
              formula=y~ x,
              se=FALSE,
              color='blue',
              method='lm') + 
  labs(title='Consumer Price Index up 32% since January 2016...\nbut month over month growth is returning to pre-pandemic levels',
       subtitle='Consumer Price Index in the United States\nJanuary 2016 to August 2024, Index = January 2016',
       caption='Source: U.S. Federal Reserve\nIndicator = CPIAUCSL',
       x='',
       y='') + 
  theme_minimal() + 
  theme(plot.title = element_text(family = 'Palatino', size=20),
        plot.subtitle = element_text(family = 'Palatino', size=13),
        axis.text = element_text(family = 'Palatino', size=10))
```
Indexing off of January 2016, the Consumer Price Index is 32% higher in August 2024. What is interesting in this plot is the distinct trajectories seen pre-pandemic, from roughly 2020-2022, and from 2022 since. This shows that the CPI seems to be returning to its pre-pandemic trajectory.

# Conclusion

In this post on Pandas DataReader, I demonstrated:

*  How to fetch data from the U.S. Federal Reserve using `pandas_datareader`
*  How to build basic plots using `matplotlib` and `plotnine`
*  How to convert Python to R objects using `reticulate::`
*  How to use `tidymodels::` to build some quick regression models and compare results

I'll be digging into some decomposed CPI data in future posts!