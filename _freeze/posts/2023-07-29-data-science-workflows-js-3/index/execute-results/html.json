{
  "hash": "7a1fa23fe255ccd2b4060124055ab129",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Science Workflows in Javascript: Part Three\"\ndescription: \"This post is from the third session led by Observable HQ\"\nauthor:\n  - name: Mickey Rafa\n    url: https://mrafa3.github.io/\n    #orcid: 0000-0002-5300-3075\ndate: 07-29-2023\ncategories: [Quarto, Javascript, data-viz, pca, environment] # self-defined categories\n#citation: \n # url: https://mrafa3.github.io/posts/2024-07-15-wikipedia-international-mens-soccer/ \nimage: biplot.png\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Introduction\n\nToday we’ll be exploring multivariate meteorological data from Mar Casado Beach, Sao Paulo (Brazil). By the end of the lesson, participants will be able to:\n\nCreate a database in a notebook using DuckDBClient.of()\nQuery the database in SQL cells\nVisualize relationships between variables\nImport and reuse existing content using import with\nPerform and visualize results of principal component analysis\nIn this session, we will work with data from da Silva et al (2019) describing monthly atmospheric and ocean data (e.g. air pressure, windspeed, tides, sea surface temperature).\n\nData source: Marcos Gonçalves da Silva, Juliana Nascimento Silva, Helena Rodrigues Fragoso, Natalia Pirani Ghilardi-Lopes (2019). Temporal series analysis of abiotic data for a subtropical Brazilian rocky shore. Data in Brief, Volume 24. ISSN 2352-3409, https://doi.org/10.1016/j.dib.2019.103873.\n\nStep 1: Combine the tables into a database\nThe data are already attached here in two parts: marCasadoAir, and marCasadoSea:\n\n\n```{ojs}\nmarCasadoAir = FileAttachment(\".//data/marCasadoAir@5.csv\").csv({typed: true}) // Date issue\n```\n\n```{ojs}\nmarCasadoSea = FileAttachment(\".//data/marCasadoSea@4.csv\").csv({typed: true}) // Date issue\n```\n\n\nWe can create a database containing both tables using DuckDBClient.of():\n\n\n```{ojs}\n// Write code to create a database called marCasadoDB, with tables 'air' and 'sea':\nmarCasadoDB = DuckDBClient.of({air: marCasadoAir, sea: marCasadoSea})\n```\n\n\nNow, open the Database pane in the right margin of your notebook. There, you can explore the schema and variables of your newly created database.\n\nStep 2: Wrangle & analyze data in a SQL cell\nWe want to combine some data from both tables in the database. The column we’re able to join by is month. We will also keep the following columns, and add a new column for season:\n\nFrom air:\n\n* month\n* meanPressure (mmHg)\n* windSpeed (kilometers per hour)\n* PAR (photoactive radiation in E/m s2)\n* meanHumidity (percent)\n* windDirection (degrees)\n\nFrom sea:\n\n* maxTide (meters)\n* minTide (meters)\n* salinity (practical salinity units)\n* seaSurfaceTemp (degrees Celsius)\n\nFrom da Silva et al (2019): “...two distinct seasons: (I) a hot and moist season from October to March (encompassing Spring and Summer) and (II) a cold and dry season from April to September (encompassing Autumn and Winter); an expected result for subtropical zones.”\n\nWe'll also add a new column, season, containing \"cool dry\" for October thru March, otherwise \"hot moist.\"\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 60 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (14): maxAirTemp, minAirTemp, maxHumidity, minHumidity, meanHumidity, m...\ndate  (1): month\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 60 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (4): seaSurfaceTemp, maxTide, minTide, salinity\ndate (1): month\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.sql .cell-code}\nselect  cast(strftime('%m', a.month) as integer) as month,\n        a.meanPressure, \n        a.windSpeed,\n        a.PAR,\n        a.meanHumidity, \n        a.windDirection,\n        s.maxTide,\n        s.minTide,\n        s.salinity,\n        s.seaSurfaceTemp,\n        CASE WHEN cast(strftime('%m', a.month) as integer) IN (10, 11, 12, 1, 2, 3) THEN 'hot moist' ELSE 'cool dry' END AS season\nfrom air as a\nleft join sea as s\non a.month = s.month\n```\n\n\n<div class=\"knitsql-table\">\n\n\nTable: Displaying records 1 - 10\n\n| month| meanPressure| windSpeed|   PAR| meanHumidity| windDirection| maxTide| minTide| salinity| seaSurfaceTemp|season    |\n|-----:|------------:|---------:|-----:|------------:|-------------:|-------:|-------:|--------:|--------------:|:---------|\n|    11|      1012.10|      5.47| 50.84|        79.86|         51.80|    1.25|    0.28|    35.50|          26.27|hot moist |\n|    12|      1011.89|      3.83| 51.48|        77.34|         71.58|    1.27|    0.26|    35.13|          26.27|hot moist |\n|     1|      1013.48|      6.22| 36.19|        79.75|         54.58|    1.30|    0.27|    35.62|          26.57|hot moist |\n|     2|      1015.67|      5.37| 35.78|        79.25|         70.64|    1.28|    0.29|    35.67|          24.82|hot moist |\n|     3|      1016.32|      4.88| 27.58|        76.40|         66.01|    1.25|    0.26|    35.77|          24.05|hot moist |\n|     4|      1017.40|      3.73| 21.69|        81.65|         71.94|    1.25|    0.25|    35.41|          22.37|cool dry  |\n|     5|      1020.16|      5.27| 25.69|        79.34|         79.75|    1.25|    0.29|    34.45|          20.73|cool dry  |\n|     6|      1018.84|      4.38| 31.20|        75.15|         90.27|    1.28|    0.29|    32.74|          18.85|cool dry  |\n|     7|      1017.23|      5.48| 33.23|        76.70|         74.55|    1.32|    0.29|    32.32|          21.05|cool dry  |\n|     8|      1015.74|      5.91| 38.72|        77.88|         56.02|    1.30|    0.31|    33.13|          21.79|cool dry  |\n\n</div>\n:::\n\n\n\n\nIf you want, you can work in SQL to wrangle & analyze an array (doesn’t have to be a database):\n\n\n::: {.cell}\n\n```{.sql .cell-code}\nSELECT cast(strftime('%m', month) as integer) as month,\n      avg(seaSurfaceTemp) as meanSST \n  FROM sea\nGROUP BY month\n```\n\n\n<div class=\"knitsql-table\">\n\n\nTable: Displaying records 1 - 10\n\n| month| meanSST|\n|-----:|-------:|\n|    11|   26.27|\n|    12|   26.27|\n|     1|   26.57|\n|     2|   24.82|\n|     3|   24.05|\n|     4|   22.37|\n|     5|   20.73|\n|     6|   18.85|\n|     7|   21.05|\n|     8|   21.79|\n\n</div>\n:::\n\n```{ojs}\nmarCasado = FileAttachment(\".//data/marCasado.csv\").csv({typed: true})\n```\n\n```{ojs}\n// Write Plot code to create a heatmap of sea surface temperature (SST) by year and month, starting from the 'cell' snippet:\nPlot.plot({\n  marks: [\n    Plot.cell(marCasado, {\n      y: d => d.month.getUTCFullYear(),\n      x: d => d.month.getUTCMonth(),\n      fill: \"seaSurfaceTemp\",\n      tip: true\n    })\n  ],\n  width: 500,\n  height: 250,\n  y: {tickFormat: \"Y\", padding: 0},\n  x: {padding: 0, tickFormat: Plot.formatMonth()}\n})\n```\n\n\n\nStep 4: Interactive data visualization\nUse import with to import content from another notebook, and replace what it expects with something new:\n\n\n```{ojs}\nimport {PlotMatrix} with {marCasado as data} from \"@observablehq/autoplot-matrix\"\n```\n\n```{ojs}\n// Use the PlotMatrix function (expecting marCasado) to create a pair plot:\nPlotMatrix(marCasado)\n```\n\n\n\nStep 5: Principal component analysis\nImports & libraries for PCA\nUse require to access methods from the ml.js package (which includes the PCA function we’ll use):\n\n\n```{ojs}\nML = require(\"https://www.lactame.com/lib/ml/6.0.0/ml.min.js\")\n```\n\n\nImport the scale and asMatrix functions from Christoph Pahmeyer’s hierarchical clustering notebook. The scale function will scale values of a property to have a mean of 0 and standard deviation of 1. We use asMatrix to get a 2D array of predictions to project our points in the PC space.\n\n\n```{ojs}\nimport {scale, asMatrix} from \"@chrispahm/hierarchical-clustering\"\n```\n\n\nScaling and PCA\nCreate a scaled version of the data, only including the numeric variables (excluding season and month) that will be included in principal component analysis:\n\n\n```{ojs}\n// Create a scaled version of the numeric variables\nmarCasadoScaled = scale(marCasado.map(({ season, month, ...rest }) => rest))\n```\n\n\nThen convert the array of objects to an array of arrays (which is what the PCA method from ml.js is expecting):\n\n\n```{ojs}\n// Convert to an array of arrays, just containing the values (no keys):\nmarCasadoArray = marCasadoScaled.map(Object.values)\n```\n\n\nNow, we’re ready to perform PCA using the PCA function in ml.js (nicknamed ML when we used require above):\n\n\n```{ojs}\n// Perform principal component analysis:\nmarCasadoPCA = new ML.PCA(marCasadoArray) // Already scaled above - otherwise can add {scale: true} here! \n```\n\n\nExplore PCA results\nUse getExplainedVariance() to see variance explained by each PC:\n\n\n```{ojs}\n// Get variance explained by each PC:\nvariancePC = marCasadoPCA.getExplainedVariance()\n```\n\n\nUse getCumulativeVariance() to see cumulative variance explained:\n\n\n```{ojs}\n// Get cumulative variance explained: \ncumulativeVariance = marCasadoPCA.getCumulativeVariance()\n```\n\n\nStep 6: Visualize PCA results\nimport with to reuse community contributions\nWe’ll again use import with to access and reuse materials, this time from Christoph Pahmeyer’s notebook on principal component analysis.\n\n\n```{ojs}\nimport {loadings} from \"@chrispahm/principal-component-analysis\"\n```\n\n```{ojs}\n// Import viewof loadings from the notebook, with marCasadoScaled as food_scaled:\nimport {viewof loadings} with {marCasadoScaled as food_scaled} from \"@chrispahm/principal-component-analysis\"\n```\n\n```{ojs}\n// Look at viewof loadings:\nloadings_df = viewof loadings\n```\n\n```{ojs}\nimport {scores} from \"@chrispahm/principal-component-analysis\"\n```\n\n```{ojs}\n// import viewof scores from the notebook, with marCasadoScaled as food_scaled and marCasado as food:\nimport {viewof scores} with {marCasadoScaled as food_scaled, marCasado as food} from \"@chrispahm/principal-component-analysis\"\n```\n\n```{ojs}\n// Look at viewof scores:\nscores_df = viewof scores\n```\n\n```{ojs}\n// Do some wrangling to get the month and season alongside scores: \nscoresCombined = scores_df.map((d, i) => ({ ...d, Name: marCasado[i].month, season: marCasado[i].season }))\n```\n\n```{ojs}\nscalingFactor = 5\n```\n\n```{ojs}\n// Create a PCA biplot with the scores and loadings\nPlot.plot({\n  marks: [\n    Plot.dot(scoresCombined, { x: \"PC1\", y: \"PC2\", fill: \"season\", r: 5 }),\n    Plot.arrow(loadings_df, {\n      x1: 0, x2: d => d.PC1 * scalingFactor, y1: 0, y2: (d) => d.PC2 * scalingFactor\n    }),\n    Plot.text(loadings_df, {\n      x: (d) => d.PC1 * scalingFactor, y: (d) => d.PC2 * scalingFactor,\n      text: \"Variable\",\n      dy: -5,\n      dx: 30,\n      fill: \"black\",\n      stroke: \"white\",\n      fontSize: 14\n    })\n  ],\n  color: { legend: true },\n  inset: 20\n}) \n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}