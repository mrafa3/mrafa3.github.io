{
  "hash": "e2d1775f1ba497d7a6cd41427cd8e0ea",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using Python to fetch data from the Federal Reserve\"\ndescription: \"Accessing, manipulating, and visualizing data from key public resources\"\nauthor:\n  - name: Mickey Rafa\n    url: https://mrafa3.github.io/\n    #orcid: 0000-0002-5300-3075\ndate: 09-15-2024\ncategories: [Python, pandas, API, data-viz, plotnine, R, Quarto, regression, matplotlib] # self-defined categories\n#citation: \n # url: https://mrafa3.github.io/posts/2024-07-15-wikipedia-international-mens-soccer/ \ncode-annotations: hover\nimage: cpi_plot.png\ndraft: true # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Introduction\n\nThe `pandas-datareader` package is a powerful tool for easily accessing financial and economic data through various APIs. In this post, we'll explore how to use it to fetch data from FRED (Federal Reserve Economic Data), the World Bank, and Yahoo Finance for S&P500 data.\n\n## Setup\n\nFirst, import the packages:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd # <1>\nfrom matplotlib import pyplot as plt # <1>\nimport pandas_datareader as pdr # <1>\nfrom datetime import datetime # <1>\n```\n:::\n\n\n1. If it's your first time running code with these libraries, you'll need to first use the pip install command. Since these are already installed for me locally, I can just import.\n\nNext, I'll set a variable for the time frame that I'd like to use for this demonstration.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstart = datetime(2016, 1, 1)\nend = datetime.now()\n```\n:::\n\n\n# Fetching Data from FRED\n\nLet's fetch the US GDP data from FRED:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ngdp_data = pdr.get_data_fred('GDP', start=start, end=end)\n\ngdp_data.reset_index(inplace=True)\n\nprint(gdp_data.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        DATE        GDP\n0 2016-01-01  18525.933\n1 2016-04-01  18711.702\n2 2016-07-01  18892.639\n3 2016-10-01  19089.379\n4 2017-01-01  19280.084\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ngdp_data.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 34 entries, 0 to 33\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype         \n---  ------  --------------  -----         \n 0   DATE    34 non-null     datetime64[ns]\n 1   GDP     34 non-null     float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 676.0 bytes\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nplt.plot(gdp_data['DATE'], gdp_data['GDP'], color='green')\nplt.suptitle('Monthly Gross Domestic Product for the United States')\nplt.title('2016-2024')\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/gdp_plot-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nnasdaq_data = pdr.get_data_fred('NASDAQ100', start, end).reset_index()\n\nsap_data = pdr.get_data_fred('SP500', start, end).reset_index()\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nsap_data.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2268 entries, 0 to 2267\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype         \n---  ------  --------------  -----         \n 0   DATE    2268 non-null   datetime64[ns]\n 1   SP500   2186 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 35.6 KB\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nplt.plot(nasdaq_data['DATE'], nasdaq_data['NASDAQ100'])\nplt.plot(sap_data['DATE'], sap_data['SP500'])\nplt.legend(['NASDAQ 100', 'S&P 500'])\nplt.show()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plt_nasdaq_sp-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\nWith just a few lines of code, we've accessed data from the U.S. Federal Reserve. The pandas-datareader package simplifies the process of fetching data, which makes it a great package to get familiar with.\n\n# Plotting with plotnine\n\nBecause I'm quite comfortable with R's ggplot syntax, I'll demonstrate how the plotnine package can visualize your Python data.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import ggplot, aes, geom_line, theme_minimal, labs\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# Fetch Colorado unemployment rate data\ncolorado_unemployment = pdr.get_data_fred('COUR', start=start, end=end).reset_index()\n\nprint(colorado_unemployment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          DATE  COUR\n0   2016-01-01   3.3\n1   2016-02-01   3.3\n2   2016-03-01   3.3\n3   2016-04-01   3.3\n4   2016-05-01   3.3\n..         ...   ...\n98  2024-03-01   3.7\n99  2024-04-01   3.7\n100 2024-05-01   3.8\n101 2024-06-01   3.8\n102 2024-07-01   3.9\n\n[103 rows x 2 columns]\n```\n\n\n:::\n:::\n\n\nNow, I'll visualize the monthly unemployment data using `plotnine`, the package to use ggplot in Python.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create the plot\n(\nggplot(colorado_unemployment, aes(x='DATE', y='COUR')) + \n  geom_line() + \n  labs(title='Colorado Unemployment Rate',\n        subtitle='2016-2024',\n        x='Date',\n        y='Unemployment Rate (%)')+\n  theme_minimal()\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<string>:2: FutureWarning: Using repr(plot) to draw and show the plot figure is deprecated and will be removed in a future version. Use plot.show().\n<Figure Size: (640 x 480)>\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_co_unemployment-5.png){width=614}\n:::\n:::\n\n\nThis code snippet does the following:\n\n*  Fetches the Colorado unemployment rate data using the FRED series ID 'COUR'.\n*  Resets the index to make the date a regular column for plotting.\n*  Uses `plotnine` (Python's implementation of ggplot2), we create a line plot of the unemployment rate over time.\n*  Makes cosmetic adjustments, including adding the minimal theme and appropriate labels.\n\nPlotnine's syntax, similar to R's ggplot2, allows for easy customization and layering of plot elements. You can further enhance this plot by adding vertical lines for recession periods, changing color schemes, or adding annotations for significant events.\n\nWhile this works, it is somewhat clunky -- especially if you're using Quarto and can render in R anyway. I'll switch over to `ggplot2` and make a more polished graphic.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncolorado_unemployment <- reticulate::py$colorado_unemployment\n```\n:::\n\n\nThen, I'll produce the graphic in `ggplot2::` (notice that the x-axis renders better this way).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/ggplot_co_unemployment-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n# Analysis of the Consumer Price Index \n\nThe Federal Reserve is the resource for gathering all data related to the Consumer Price Index. There are many ways to look at this, including decomposing by the type of good, looking at it over different horizons or localities, and more. \nFor this demo, I'll just look at the U.S. city average for all urban consumers.[^1] Again, I'll use `pandas_datareader` and pass through some simple arguments to fetch the data.\n\n[^1]: The Federal Reserve website is a great place to comb through to see all the available data (https://fred.stlouisfed.org/). \n\n\n::: {.cell}\n\n```{.python .cell-code}\ncpi = pdr.get_data_fred('CPIAUCSL', start=start, end=end).reset_index()\n```\n:::\n\nFor this section, I'd like to work in R, so I'll use `reticulate::` to make it an R object.\n\n\n::: {.cell}\n\n:::\n\n\nWhen you're working with CPI data, it is common to index the data, or compare recent values to a historical value. I'll create an `indexed_cpi_2016` field, along with a `date_seq` field to allow some simple linear models.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncpi %>% \n  ggplot(aes(x=DATE,\n             y=indexed_cpi_2016)) + \n  geom_line() + \n  labs(title='Consumer Price Index in the United States',\n       subtitle='January 2016 to August 2024, Index = January 2016',\n       caption='Source: U.S. Federal Reserve\\nIndicator = CPIAUCSL',\n       x='',\n       y='') + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ggplot_cpi-1.png){fig-align='center' width=960}\n:::\n:::\n\n\nThis plot shows a clear rise in the indexed CPI from 2016 to present day. What stands out, too, is that there appear to be some distinct trends (possibly three) -- pre-pandemic, pandemic, and post-pandemic. I'd like to extend this mini-analysis to find the slopes of these periods and plot them on the above graphic.\n\n\n::: {.cell}\n\n:::\n\n\nTo do so, I'll create a function and use `tidymodels::` to build linear models that I can easily create and compare with one another.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_cpi_model <- function(df) {\n  lm_model <- linear_reg() %>% set_engine(\"lm\") # <2>\n  lm_fit <- lm_model %>% # <3>\n    fit(indexed_cpi_2016 ~ date_seq, data = df) # <3>\n  return(lm_fit)\n}\n```\n:::\n\n\n2. This sets up the model type as a simple linear model.\n3. This is the function that will take in the `df` parameter and run the model\n\nThese create a `parsnip::` model object, which we can then explore the model results in tidy dataframes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_1 <- fit_cpi_model(cpi %>% filter(DATE <= '2020-03-01'))\nlm_2 <- fit_cpi_model(cpi %>% filter(DATE > '2020-03-01' & DATE <= '2022-06-01'))\nlm_3 <- fit_cpi_model(cpi %>% filter(DATE > '2022-06-01'))\n```\n:::\n\n\nThe `broom::tidy()` function returns a row for each coefficient your model, which I'll use to compare the slopes of the different periods.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n     model     term    estimate\n1 Period 1 date_seq 0.001841866\n2 Period 2 date_seq 0.006155374\n3 Period 3 date_seq 0.003386268\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\nHere's what this tells us:\n\n*  Pre-pandemic slope of .002\n*  Pandemic-era slope of .006\n*  Post-pandemic slope of .003\n\nThis is also apparent visually, as seen below.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncpi %>% \n  ggplot(aes(x=DATE,\n             y=indexed_cpi_2016)) + \n  geom_line() + \n  geom_smooth(data=. %>% filter(DATE <= '2020-03-01'),\n              formula=y~ x,\n              se=FALSE,\n              color='blue',\n              method='lm') + \n  geom_smooth(data=. %>% filter(DATE > '2020-03-01' & DATE <= '2022-06-01'),\n              formula=y~ x,\n              se=FALSE,\n              color='orange',\n              method='lm') + \n  geom_smooth(data=. %>% filter(DATE > '2022-06-01'),\n              formula=y~ x,\n              se=FALSE,\n              color='blue',\n              method='lm') + \n  labs(title='Consumer Price Index up 32% since January 2016...\\nbut month over month growth is returning to pre-pandemic levels',\n       subtitle='Consumer Price Index in the United States\\nJanuary 2016 to August 2024, Index = January 2016',\n       caption='Source: U.S. Federal Reserve\\nIndicator = CPIAUCSL',\n       x='',\n       y='') + \n  theme_minimal() + \n  theme(plot.title = element_text(family = 'Palatino', size=20),\n        plot.subtitle = element_text(family = 'Palatino', size=13),\n        axis.text = element_text(family = 'Palatino', size=10))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ggplot_cpi_polished-1.png){fig-align='center' width=960}\n:::\n:::\n\nIndexing off of January 2016, the Consumer Price Index is 32% higher in August 2024. What is interesting in this plot is the distinct trajectories seen pre-pandemic, from roughly 2020-2022, and from 2022 since. This shows that the CPI is returning to its pre-pandemic trajectory.\n\n# Conclusion\n\nIn this post on Pandas DataReader, I demonstrated:\n\n*  How to fetch data from the U.S. Federal Reserve and World Bank using `pandas_datareader`\n*  How to build basic plots using `matplotlib` and `plotnine`\n*  How to convert Python to R objects using `reticulate::`\n*  How to use `tidymodels::` to build some quick regression models and compare results\n\nI'll be digging into some decomposed CPI analysis in future posts!",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}