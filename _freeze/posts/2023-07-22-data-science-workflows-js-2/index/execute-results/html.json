{
  "hash": "fa5f0bab8eb0a270ce7c8e976d583390",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Science Workflows in Javascript: Part Two\"\ndescription: \"This post is from the second session led by Observable HQ\"\nauthor:\n  - name: Mickey Rafa\n    url: https://mrafa3.github.io/\n    #orcid: 0000-0002-5300-3075\ndate: 07-11-2023\ncategories: [Quarto, Javascript, data-viz, regression] # self-defined categories\n#citation: \n # url: https://mrafa3.github.io/posts/2024-07-15-wikipedia-international-mens-soccer/ \n#image: js_plot.png\ndraft: true # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Introduction\n\nLearning objectives\nAfter following along in Session #2, participants will be able to:\n\nAccess remote data from an online repository with d3.csv\nMerge and wrangle data from multiple files\nCreate interactive exploratory data viz with Observable Plot and Inputs\nReuse community examples content using imports\nPerform and visualize cluster analysis by k-means\nPublish outcomes with embeds\nBackground\nIn this session, we’ll recreate the curated penguins dataset from scratch by accessing the raw data from the Environmental Data Initiative Data Portal, wrangling it to match the curated version, exploring the data in interactive data visualizations, then doing some cluster analysis by k-means and hierarchical clustering.\n\nThe penguins data contains size measurements and blood isotope analysis for nesting pairs of three penguin species (Adélie, gentoo, and chinstrap), collected on islands near Palmer Archipelago, Antarctica, from 2007 - 2009 by Dr. Kristen B. Gorman and colleagues (Gorman et al. 2016).\n\nGorman et al (2014). Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus pygoscelis). PLoS ONE, 9(3): e90081. https://dx.plos.org/10.1371/journal.pone.0090081.\n\nStep 0: Fork this notebook!\nFork this follow-along notebook to make your own copy, in your own account. Working in your own fork will ensure that changes you make during the session are saved.\n\nNote: You can work without an account by making changes in tinker mode (not recommended), but your changes will not be saved, and refreshing the page will erase any changes.\n\n**Step 1: Get the raw data from Environmental Data Initiative using d3.csv()**\n\nFirst, we’ll access the penguins data for each of the three species from the Environmental Data Initiative using d3.csv(). The links for the three species are:\n\nGentoo penguins: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.220.7&entityid=e03b43c924f226486f2f0ab6709d2381\nAdélie penguins: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.219.5&entityid=002f3893385f710df69eeebe893144ff\nChinstrap penguins: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.221.8&entityid=fe853aa8f7a59aa84cdd3197619ef462\nLet’s store these in our notebook as gentoo, adelie, and chinstrap (note that they are stored as arrays of objects, with all properties as characters). We will use d3.autoType to parse the data (assign types), otherwise they will be automatically interpreted as characters.\n\nLearn more about accessing data from remote files and APIs.\n\n*Note: `d3.csv()` was not working, so I've switched this to `read_csv()` from R.*\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngentoo <- read_csv(\"https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.220.7&entityid=e03b43c924f226486f2f0ab6709d2381\")\n\nadelie <- read_csv(\"https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.219.5&entityid=002f3893385f710df69eeebe893144ff\")\n\nchinstrap <- read_csv(\"https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-pal.221.8&entityid=fe853aa8f7a59aa84cdd3197619ef462\")\n```\n:::\n\n\n**Step 2: Merge & wrangle the data**\n\nOur first step will be to get these all into a single array of objects. Since they all have the same properties, in the same order, we can use the concat() method to combine them.\n\n\n```{ojs}\n// Make combined version, penguinsCombo, here\npenguinsCombo = adelie.concat(gentoo, chinstrap)\n```\n\n\nRecreate the curated penguins data in JS\nLet’s wrangle the data in JavaScript to recreate the curated penguins data, updating to only keep and rename the following:\n\n* Species (renamed species, and limited to only the first word)\n* Island (renamed island)\n* Sex (renamed sex, and converted to lowercase)\n* Culmen Length (mm) (renamed bill_length_mm)\n* Culmen Depth (mm) (renamed bill_depth_mm)\n* Body Mass (g) (renamed body_mass_g)\n* Flipper Length (mm) (renamed flipper_length_mm)\n\n\n```{ojs}\n// Create the wrangled version of penguins here: \npenguins = penguinsCombo.map((d) => ({\n  species: d.Species.split(\" \")[0],\n  island: d.Island,\n  sex: d.Sex == null || d.Sex == \".\" ? null : d.Sex.toLowerCase(),\n  bill_length_mm: d[\"Culmen Length (mm)\"],\n  bill_depth_mm: d[\"Culmen Depth (mm)\"],\n  body_mass_g: d[\"Body Mass (g)\"],\n  flipper_length_mm: d[\"Flipper Length (mm)\"]})) \n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}