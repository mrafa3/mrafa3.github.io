[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Part Three: Exploring even smaller geographies with tidycensus\n\n\n\nR\n\n\ntidyverse\n\n\ntidycensus\n\n\nmapping\n\n\napi\n\n\n\nThis post shows how to fetch data at smaller scales for analysis of Census data\n\n\n\nMickey Rafa\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart Two: Wrangling Census data for longitudinal analysis of child poverty\n\n\n\nR\n\n\ndata-viz\n\n\ntidyverse\n\n\ntidycensus\n\n\napi\n\n\njavascript\n\n\npurrr\n\n\n\nThis post shows how to fetch many years of data simply, unlocking longitudinal analysis of Census data\n\n\n\nMickey Rafa\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up an EPA air quality database using DuckDB\n\n\n\nR\n\n\ntidyverse\n\n\nduckdb\n\n\nenvironment\n\n\nsql\n\n\napi\n\n\n\nThis post uses the RAQSAPI package to access the EPA API and query the results with DuckDB\n\n\n\nMickey Rafa\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart One: Exploring child poverty data with the tidycensus R package\n\n\n\nR\n\n\ntidyverse\n\n\nmapping\n\n\ngt\n\n\ntidycensus\n\n\napi\n\n\n\nThis post uses the tidycensus package to access the Census API and visualize data on child poverty in the U.S.\n\n\n\nMickey Rafa\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring interactive mapping with mapboxgl\n\n\n\nR\n\n\ntidyverse\n\n\nmapping\n\n\n\nThis post explores some mapboxgl features\n\n\n\nMickey Rafa\n\n\nAug 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrainTree SQL challenge\n\n\n\nSQL\n\n\nQuarto\n\n\n\nThis post works through the SQL challenges used by PayPal\n\n\n\nMickey Rafa\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery comparison: SQL, R, and Python using Chicago Employees dataset\n\n\n\nR\n\n\nSQL\n\n\nPython\n\n\nQuarto\n\n\ngenerative-AI\n\n\n\nThis post demonstrates how to run these languages in Quarto\n\n\n\nMickey Rafa\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Workflows in Javascript: Part Three\n\n\n\nQuarto\n\n\nJavascript\n\n\ndata-viz\n\n\npca\n\n\nenvironment\n\n\n\nThis post is from the third session led by Observable HQ\n\n\n\nMickey Rafa\n\n\nJul 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Workflows in Javascript: Part Two\n\n\n\nQuarto\n\n\nJavascript\n\n\ndata-viz\n\n\ncluster-analysis\n\n\nenvironment\n\n\n\nThis post is from the second session led by Observable HQ\n\n\n\nMickey Rafa\n\n\nJul 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Science Workflows in Javascript: Part One\n\n\n\nQuarto\n\n\nJavascript\n\n\ndata-viz\n\n\nregression\n\n\nenvironment\n\n\n\nThis post is from the first session led by Observable HQ\n\n\n\nMickey Rafa\n\n\nJul 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding beautiful tables with the gt:: package in R\n\n\n\nR\n\n\nweb-scraping\n\n\ngt\n\n\nsports\n\n\n\nThis post outlines how to quickly scrape and clean data from Wikipedia and build a beautiful table in R\n\n\n\nMickey Rafa\n\n\nDec 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPART TWO: Mapping of African Health Clusters\n\n\n\nR\n\n\ndata-viz\n\n\ntidyverse\n\n\ninternational-development\n\n\ncluster-analysis\n\n\nmapping\n\n\n\nCreating maps of cluster results using ggplot\n\n\n\nMickey Rafa\n\n\nJun 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPART ONE: Cluster Analysis of African Health Outcomes\n\n\n\nR\n\n\ndata-viz\n\n\ntidyverse\n\n\ninternational-development\n\n\ncluster-analysis\n\n\n\nExploring how African countries cluster based on their health outcomes\n\n\n\nMickey Rafa\n\n\nJun 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperimenting with distance as a concept for SDG achievement\n\n\n\nR\n\n\ndata-viz\n\n\ntidyverse\n\n\ninternational-development\n\n\ncluster-analysis\n\n\nmapping\n\n\n\nExploring how to conceptualize and visualize distance from Sustainable Development Goal targets\n\n\n\nMickey Rafa\n\n\nApr 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nAnimating the Gapminder dataset using gganimate\n\n\n\nR\n\n\ndata-viz\n\n\ntidyverse\n\n\ngganimate\n\n\n\nThis post outlines how to easily add animation to ggplot graphics\n\n\n\nMickey Rafa\n\n\nOct 15, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Gapminder data using nested models in R\n\n\n\nR\n\n\nregression\n\n\ndata-viz\n\n\ntidyverse\n\n\ninternational-development\n\n\n\nThis post outlines the value in building nested models using the purrr and broom packages\n\n\n\nMickey Rafa\n\n\nOct 1, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mickey Rafa",
    "section": "",
    "text": "My name is Mickey – welcome to my portfolio website! I’m an analytics leader with nearly a decade of experience in high-growth environments, in both non-profit and for-profit organizations. I specialize in turning data into insights, improving the accessibility of dashboards and reports, and creating compelling data stories.\nOn this site, I include a selection of data science and viz projects that showcase the breadth of work that I’ve completed.\nLet’s connect! Feel free to reach out to me on LinkedIn or send me an email.\n\nEducation\n\nMS in Business Analytics | University of Denver\nMA in International Studies | University of Denver\nBA in Political Science | West Virginia University\n\nWork Experience\n\nSr. Manager, Employer Analytics | Guild Education\nAssistant Director of Research | Pardee Center for International Futures, University of Denver\n\nPeer-Reviewed Publications\n\nMoyer, J., Matthews, A., Rafa, M., Xiong, Y. “Identifying Patterns in the Structural Drivers of Intrastate Conflict.” British Journal of Political Science. (2022).\nWang, X., Rafa, M., Moyer, J., Li, J., Scheer, J., Sutton, P. “Estimation and Mapping of Sub-National GDP in Uganda Using NPP-VIIRS Imagery.” Remote Sensing. (2019)."
  },
  {
    "objectID": "posts/2024-08-20-tidycensus-exploration-pt2/index.html",
    "href": "posts/2024-08-20-tidycensus-exploration-pt2/index.html",
    "title": "Part Two: Wrangling Census data for longitudinal analysis of child poverty",
    "section": "",
    "text": "In Part One, I demonstrated how to fetch data and do some basic analysis of U.S. Census data. Each API call with the tidycensus:: package can only be for one year of data, so to do longitudinal analysis requires some additional wrangling.\nIn this post, I’ll build a script that iterates through the available years, fetches the data, then combines the data into a single dataframe. Then, I’ll unpack some of the trends seen in child poverty in Colorado.\n\n\n\nlibrary(tidyverse)\nlibrary(tidycensus)\n1library(scales)\n2library(gt)\n3library(glue)\n\n4# census_api_key('INSERT KEY HERE', install = TRUE)\n\n\n1\n\nLoading the scales:: package to transform ggplot scales simply (some people choose to explicitly define scales:: in their code rather than loading the library).\n\n2\n\nThe gt():: library provides functionality for creating ggplot-esque tables.\n\n3\n\nThe glue:: package allows for simple addition of HTML to ggplot graphics.\n\n4\n\nThe first time that you’re working with the tidycensus:: package, you need to request an API key at https://api.census.gov/data/key_signup.html. The install= argument will install your personal key to the .Renviron file, and you won’t need to use the census_api_key() function again."
  },
  {
    "objectID": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#setup",
    "href": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#setup",
    "title": "Part Two: Wrangling Census data for longitudinal analysis of child poverty",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidycensus)\n1library(scales)\n2library(gt)\n3library(glue)\n\n4# census_api_key('INSERT KEY HERE', install = TRUE)\n\n\n1\n\nLoading the scales:: package to transform ggplot scales simply (some people choose to explicitly define scales:: in their code rather than loading the library).\n\n2\n\nThe gt():: library provides functionality for creating ggplot-esque tables.\n\n3\n\nThe glue:: package allows for simple addition of HTML to ggplot graphics.\n\n4\n\nThe first time that you’re working with the tidycensus:: package, you need to request an API key at https://api.census.gov/data/key_signup.html. The install= argument will install your personal key to the .Renviron file, and you won’t need to use the census_api_key() function again."
  },
  {
    "objectID": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#fetching-from-the-tidycensus-api",
    "href": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#fetching-from-the-tidycensus-api",
    "title": "Part Two: Wrangling Census data for longitudinal analysis of child poverty",
    "section": "Fetching from the tidycensus:: API",
    "text": "Fetching from the tidycensus:: API\n\n5years &lt;- seq(2005, 2022) %&gt;%\n6  setdiff(2020)\n\n\n5\n\nData for the ACS-1 product begins in 2005.\n\n6\n\nDue to the COVID-19 pandemic, the U.S. Census Bureau does not have standard ACS products available for 2020. The setdiff() function removes 2020 from the vector.\n\n\n\n\nNext, I’ll define a function to fetch the ACS data for each year in the vector.\n\nfetch_acs_data &lt;- function(year) {\n  get_acs(geography = \"county\", \n          state = \"Colorado\",\n          survey = 'acs1',\n          variables = c(male_u5_pop = 'B01001_003', \n                        female_u5_pop = 'B01001_027', \n                        male_u5_poverty = 'B17001_004', \n                        female_u5_poverty = 'B17001_018'),\n          year = year,\n          output = 'wide') %&gt;% \n    mutate(year = year)\n}\n\nThen, I’ll use purrr::map_df() to apply each year to the fetch_acs_data() function that I created, which will result in a single dataframe of all years.\n\ncombined_acs_data &lt;- map_df(years, fetch_acs_data)"
  },
  {
    "objectID": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#data-wrangling",
    "href": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#data-wrangling",
    "title": "Part Two: Wrangling Census data for longitudinal analysis of child poverty",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nCreating some fields to combine gender-based poverty estimates and calculate a percent of the child population measure\n\n\ncombined_acs_data &lt;- combined_acs_data %&gt;% \n  mutate(total_u5_popE = male_u5_popE + female_u5_popE,\n         total_u5_povertyE = male_u5_povertyE + female_u5_povertyE,\n         perc_u5_poverty = total_u5_povertyE / total_u5_popE)\n\n\nCreating a county field that cleans the county_state field to only include the county name\n\n\ncombined_acs_data &lt;- combined_acs_data %&gt;% \n  mutate(county = str_remove(NAME, \" County.*\")) %&gt;% \n  select(county, everything())\n\n\nReading in a table that maps Colorado’s counties to a region of the state\n\n\ncolorado_regions &lt;- read_csv('.//data/colorado_regions.csv', show_col_types = FALSE) %&gt;%\n  mutate(region = as.factor(region))\n\n\n(Finally) creating the combined_acs_data dataframe for longitudinal analysis\n\n\ncombined_acs_data &lt;- combined_acs_data %&gt;% \n  left_join(x=.,\n            y=colorado_regions,\n            by='county')"
  },
  {
    "objectID": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#footnotes",
    "href": "posts/2024-08-20-tidycensus-exploration-pt2/index.html#footnotes",
    "title": "Part Two: Wrangling Census data for longitudinal analysis of child poverty",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nScreenshot taken from the ACS 2018 Handbook, found here: https://www.census.gov/content/dam/Census/library/publications/2018/acs/acs_general_handbook_2018_ch03.pdf.↩︎\nBy default the tidycensus:: API provides the margin of error at the 90% confidence interval, but you can change this with the moe_level argument within get_acs().↩︎"
  },
  {
    "objectID": "posts/2024-07-24-chicago-employee-query-comparison/index.html",
    "href": "posts/2024-07-24-chicago-employee-query-comparison/index.html",
    "title": "Query comparison: SQL, R, and Python using Chicago Employees dataset",
    "section": "",
    "text": "This project has three purposes:\n\nTo show how to run R, SQL, and Python all interchangeably in a Quarto document\nTo compare the ease of writing code using dplyr (R), SQL, and pandas (Python)\nTo include some demonstration of SQL in my portfolio (which is often not included but remains a critical skill)\n\n\n\n\nRequired packages:\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(httr)           #to fetch the data\nlibrary(janitor)        #for the clean_names() function for data cleaning\nlibrary(reticulate)     #to enable Python within R\nlibrary(DBI)            #to establish in-memory database of R dataframe\nlibrary(RSQLite)        #for SQLite engine\nlibrary(lubridate)      #for functions to handle dates\n\nAbout the dataset:\nThis dataset is from data.world, and includes information from Chicago’s Department of Human Resources for city employees in 2017. It’s a simple dataset to allow for comparisons across languages.\n\n# reading as a temporary file, then saving as df\nGET(\"https://query.data.world/s/hu5dkviuxd6k2ipuhpxjuyuds7aplu?dws=00000\", write_disk(tf &lt;- tempfile(fileext = \".xls\")))\n\nResponse [https://download.data.world/file_download/wbezchicago/chicago-employee-positions-and-salaries-for-2017/Employee%20Salary%20Data%20as%20of%20Sept.%202017.xls?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50Om1yYWZhMyIsImlzcyI6ImFnZW50Om1yYWZhMzo6ODg0MjQ2ZDItMTgzMy00NmZjLTk2YTMtZjQ2MWMzMDJjOTZiIiwiaWF0IjoxNzIxODc0NzgyLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX2VudGVycHJpc2VfYWRtaW4iLCJ1c2VyX2FwaV9yZWFkIiwidXNlcl9hcGlfd3JpdGUiXSwiZ2VuZXJhbC1wdXJwb3NlIjpmYWxzZSwidXJsIjoiMjM2ZDZlZGQ3NjdkZmVmOGRjYzM0Mzg3YTExMDQ1N2EzMmU1OGY3ZSJ9.oTr9PF0rrsLdVhewmy2v1vRgYvT0jy_PBmqhmrufaRSB25PEm48ZPxvswiSrZw8bNaACxDWpxwBiJVCVSaM-Zg]\n  Date: 2024-07-26 20:16\n  Status: 200\n  Content-Type: application/vnd.ms-excel\n  Size: 4.72 MB\n&lt;ON DISK&gt;  /var/folders/ck/dmgn8lbx6vl8sl89vlhr0sv00000gn/T//Rtmp44XQRB/filed76165bf9508.xls\n\n\n\ndf &lt;- read_excel(tf) %&gt;% \n  #clean_names() to make all column names lowercase\n  clean_names()\n\n\n\nRows: 32,806\nColumns: 8\n$ name                           &lt;chr&gt; \"AARON,  JEFFERY M\", \"AARON,  KARINA\", …\n$ title                          &lt;chr&gt; \"SERGEANT\", \"POLICE OFFICER (ASSIGNED A…\n$ department                     &lt;chr&gt; \"POLICE\", \"POLICE\", \"FLEET AND FACILITY…\n$ salary_annual                  &lt;dbl&gt; 101442.0, 94122.0, 101592.0, 110064.0, …\n$ original_hire_date             &lt;dttm&gt; 2005-09-26, 2005-09-26, 1991-08-01, 19…\n$ start_date_in_present_position &lt;dttm&gt; 2016-06-01, 2017-04-16, 2000-05-01, 20…\n$ salary_basis                   &lt;chr&gt; \"SALARY\", \"SALARY\", \"SALARY\", \"SALARY\",…\n$ employment_category            &lt;chr&gt; \"Fulltime-Regular\", \"Fulltime-Regular\",…\n\n\n\n\n\nThe DBI:: package allows you to create an in-memory database to query against. The DBI project site is a great place to learn more about it. I’ll start by doing some initial setup and establishing the connection between the R dataframe and the SQL table name that I’ll query.\n\ncon &lt;- DBI::dbConnect(SQLite(), \":memory:\")\nDBI::dbWriteTable(conn = con, name = \"df\", value = df, field.types = c(\"original_hire_date\" = \"Date\"), row.names = FALSE)\n\nThe reticulate:: package allows for executing Python code in an R environment. The reticulate project site includes useful examples for getting up and running with Python in R. This package includes an r_to_py() function that is needed to convert an R dataframe into a pandas dataframe.\n\npy$df &lt;- r_to_py(df)\n\nWhen inserting a code chunk to your Markdown file, it originally defaults to ‘{r}’. You can simply change this to ‘python’ or ‘sql’ and, with the above set up, the code works beautifully in a Quarto document!\nIn the sections that follow, I used ChatGPT to generate prompts as querying exercises. For the initial code chunks,"
  },
  {
    "objectID": "posts/2024-07-24-chicago-employee-query-comparison/index.html#purpose",
    "href": "posts/2024-07-24-chicago-employee-query-comparison/index.html#purpose",
    "title": "Query comparison: SQL, R, and Python using Chicago Employees dataset",
    "section": "",
    "text": "This project has three purposes:\n\nTo show how to run R, SQL, and Python all interchangeably in a Quarto document\nTo compare the ease of writing code using dplyr (R), SQL, and pandas (Python)\nTo include some demonstration of SQL in my portfolio (which is often not included but remains a critical skill)"
  },
  {
    "objectID": "posts/2024-07-24-chicago-employee-query-comparison/index.html#setup-and-data-preparation",
    "href": "posts/2024-07-24-chicago-employee-query-comparison/index.html#setup-and-data-preparation",
    "title": "Query comparison: SQL, R, and Python using Chicago Employees dataset",
    "section": "",
    "text": "Required packages:\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(httr)           #to fetch the data\nlibrary(janitor)        #for the clean_names() function for data cleaning\nlibrary(reticulate)     #to enable Python within R\nlibrary(DBI)            #to establish in-memory database of R dataframe\nlibrary(RSQLite)        #for SQLite engine\nlibrary(lubridate)      #for functions to handle dates\n\nAbout the dataset:\nThis dataset is from data.world, and includes information from Chicago’s Department of Human Resources for city employees in 2017. It’s a simple dataset to allow for comparisons across languages.\n\n# reading as a temporary file, then saving as df\nGET(\"https://query.data.world/s/hu5dkviuxd6k2ipuhpxjuyuds7aplu?dws=00000\", write_disk(tf &lt;- tempfile(fileext = \".xls\")))\n\nResponse [https://download.data.world/file_download/wbezchicago/chicago-employee-positions-and-salaries-for-2017/Employee%20Salary%20Data%20as%20of%20Sept.%202017.xls?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50Om1yYWZhMyIsImlzcyI6ImFnZW50Om1yYWZhMzo6ODg0MjQ2ZDItMTgzMy00NmZjLTk2YTMtZjQ2MWMzMDJjOTZiIiwiaWF0IjoxNzIxODc0NzgyLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX2VudGVycHJpc2VfYWRtaW4iLCJ1c2VyX2FwaV9yZWFkIiwidXNlcl9hcGlfd3JpdGUiXSwiZ2VuZXJhbC1wdXJwb3NlIjpmYWxzZSwidXJsIjoiMjM2ZDZlZGQ3NjdkZmVmOGRjYzM0Mzg3YTExMDQ1N2EzMmU1OGY3ZSJ9.oTr9PF0rrsLdVhewmy2v1vRgYvT0jy_PBmqhmrufaRSB25PEm48ZPxvswiSrZw8bNaACxDWpxwBiJVCVSaM-Zg]\n  Date: 2024-07-26 20:16\n  Status: 200\n  Content-Type: application/vnd.ms-excel\n  Size: 4.72 MB\n&lt;ON DISK&gt;  /var/folders/ck/dmgn8lbx6vl8sl89vlhr0sv00000gn/T//Rtmp44XQRB/filed76165bf9508.xls\n\n\n\ndf &lt;- read_excel(tf) %&gt;% \n  #clean_names() to make all column names lowercase\n  clean_names()\n\n\n\nRows: 32,806\nColumns: 8\n$ name                           &lt;chr&gt; \"AARON,  JEFFERY M\", \"AARON,  KARINA\", …\n$ title                          &lt;chr&gt; \"SERGEANT\", \"POLICE OFFICER (ASSIGNED A…\n$ department                     &lt;chr&gt; \"POLICE\", \"POLICE\", \"FLEET AND FACILITY…\n$ salary_annual                  &lt;dbl&gt; 101442.0, 94122.0, 101592.0, 110064.0, …\n$ original_hire_date             &lt;dttm&gt; 2005-09-26, 2005-09-26, 1991-08-01, 19…\n$ start_date_in_present_position &lt;dttm&gt; 2016-06-01, 2017-04-16, 2000-05-01, 20…\n$ salary_basis                   &lt;chr&gt; \"SALARY\", \"SALARY\", \"SALARY\", \"SALARY\",…\n$ employment_category            &lt;chr&gt; \"Fulltime-Regular\", \"Fulltime-Regular\",…"
  },
  {
    "objectID": "posts/2024-07-24-chicago-employee-query-comparison/index.html#setting-up-python-and-sql-to-execute",
    "href": "posts/2024-07-24-chicago-employee-query-comparison/index.html#setting-up-python-and-sql-to-execute",
    "title": "Query comparison: SQL, R, and Python using Chicago Employees dataset",
    "section": "",
    "text": "The DBI:: package allows you to create an in-memory database to query against. The DBI project site is a great place to learn more about it. I’ll start by doing some initial setup and establishing the connection between the R dataframe and the SQL table name that I’ll query.\n\ncon &lt;- DBI::dbConnect(SQLite(), \":memory:\")\nDBI::dbWriteTable(conn = con, name = \"df\", value = df, field.types = c(\"original_hire_date\" = \"Date\"), row.names = FALSE)\n\nThe reticulate:: package allows for executing Python code in an R environment. The reticulate project site includes useful examples for getting up and running with Python in R. This package includes an r_to_py() function that is needed to convert an R dataframe into a pandas dataframe.\n\npy$df &lt;- r_to_py(df)\n\nWhen inserting a code chunk to your Markdown file, it originally defaults to ‘{r}’. You can simply change this to ‘python’ or ‘sql’ and, with the above set up, the code works beautifully in a Quarto document!\nIn the sections that follow, I used ChatGPT to generate prompts as querying exercises. For the initial code chunks,"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "PART TWO: Data Manipulation and Visualization Basics using R\n\n\n\nR\n\n\ntidyverse\n\n\nggplot\n\n\ndata-viz\n\n\ndomestic-politics\n\n\n\nThis skills workshop introduced R and the tidyverse to Master’s students at the University of Denver\n\n\n\nMickey Rafa\n\n\nMay 15, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPART ONE: Data Manipulation and Visualization Basics using R\n\n\n\nR\n\n\ntidyverse\n\n\nggplot\n\n\ndata-viz\n\n\ninternational-development\n\n\n\nThis skills workshop introduced R and the tidyverse to Master’s students at the University of Denver\n\n\n\nMickey Rafa\n\n\nMay 15, 2018\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "In progress"
  }
]